<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kvm on Are you kidding?</title>
    <link>https://nimisolo.github.io/tags/kvm/index.xml</link>
    <description>Recent content in Kvm on Are you kidding?</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <atom:link href="https://nimisolo.github.io/tags/kvm/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Linux内核idle进程分析</title>
      <link>https://nimisolo.github.io/post/mwait_idle/</link>
      <pubDate>Sun, 19 Feb 2017 08:42:58 +0800</pubDate>
      
      <guid>https://nimisolo.github.io/post/mwait_idle/</guid>
      <description>

&lt;h3 id=&#34;写作背景&#34;&gt;写作背景&lt;/h3&gt;

&lt;p&gt;在当前KVM实现中，当vcpu中执行HLT指令时会发生VMexit，KVM模块中会进入&lt;code&gt;kvm_vcpu_block&lt;/code&gt;函数，从前此函数会快速将vcpu线程schedule out，但在配置了halt_poll_ns的情况下，当条件满足时会适当的busy loop一段时间，代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void kvm_vcpu_block(struct kvm_vcpu *vcpu)
{
	...
		do {
			/*
			 * This sets KVM_REQ_UNHALT if an interrupt
			 * arrives.
			 */
			if (kvm_vcpu_check_block(vcpu) &amp;lt; 0) {
				++vcpu-&amp;gt;stat.halt_successful_poll;
				if (!vcpu_valid_wakeup(vcpu))
					++vcpu-&amp;gt;stat.halt_poll_invalid;
				goto out;
			}
			cur = ktime_get();
		} while (single_task_running() &amp;amp;&amp;amp; ktime_before(cur, stop));	
	...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;当vcpu此时不再是halt状态 或 当前pcpu上不止一个可运行task 或 busy loop时间到期 这三者任一满足时将退出busy loop，在busy loop过程中CPU使用率肯定会冲高到100%。可是我们不想将这段时间被TOP工具即pmcint工具（利用PMU）统计到，前者可以通过修改内核cputime.c中的几个统计代码来实现，但是后者的话稍微有点麻烦。pmcint工具利用了PMU硬件打点的原理，我们没法修改统计，最后想到的办法是改造此busy loop，在其中进入C1 state，这样的话PMU计数器会暂停，从而使得pmcint暂停打点，这样既确保了vcpu性能，又无法使用户看到很高的占用率。&lt;/p&gt;

&lt;p&gt;细想一下，此处busy loop的好处是啥？无非就是在条件满足的情况下不要将vcpu线程切换出去，否则来回切换势必使得vcpu线程被唤醒不够及时，导致虚拟机性能受影响。这样来说的话，我们在busy loop中调用HLT/MWAIT也能起到一样的效果：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;如果使用MWAIT，我们可以用MONITOR监控让busy loop结束的变量，这样当需要结束时MWAIT会被broken，从而与此前流程一样。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果使用HLT，则我们需要根据stop设置一个backend hrtimer，保证我们肯定能够从HLT中出来。（但是，这个方式肯定不如上述代码的实现，因为HLT的broken事件中不包括内存监控，它没法及时监控到nr_running的变化，这可能会导致调度不及时）&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;font color=red&gt;&lt;strong&gt;[更新]&lt;/strong&gt;突然想到一个此处换做HLT/MWAIT的一个优势：在开启硬件超线程的host上，如果同一core上的一个硬件线程的vcpu1进行halt_poll_ns而另外个硬件线程上的vcpu2在运行业务，那么这种做法或许比社区的好，因为vcpu1 exit执行HLT/MWAIT指令后，该core的硬件资源此时能够完全给另一个硬件线程独占，该线程性能会因资源独占而变好。&lt;/font&gt;&lt;/p&gt;

&lt;h3 id=&#34;cpu-cstates&#34;&gt;CPU Cstates&lt;/h3&gt;

&lt;p&gt;Cstates是ACPI规范中引入的，具体的可以看acpi spec，下面内容摘自&lt;a href=&#34;http://www.expreview.com/25426.html&#34;&gt;Haswell芯光大道之六：C-States十种状态解析&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&#34;三种常见cpu工作状态简介&#34;&gt;三种常见CPU工作状态简介&lt;/h4&gt;

&lt;p&gt;常见的CPU工作状态包含S-States、C-States和P-States三种，其中&lt;strong&gt;S-States（Sleeping states）指系统睡眠状态&lt;/strong&gt;，&lt;strong&gt;C-States（CPU Power states）指CPU电源状态&lt;/strong&gt;，而&lt;strong&gt;P-States（CPU Performance states）则指CPU性能状态&lt;/strong&gt;。当然除了这三种外，还有G-States（全局状态）和D-States（设备状态）。&lt;/p&gt;

&lt;p&gt;S-States很好理解，就是你手动点击“睡眠”，或者达到一定的待机时间（根据系统电源管理设置而定）进入睡眠状态，S0就是指正常运作。而C-States和P-States看起来也很类似，都会调节处理器的核心电压、电流以及频率，因此经常被混淆。其实他们的区别也是很明显的，不过我们首先要梳理一下上面这三种状态的关系。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://nimisolo.github.io/intel-power-state.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;S-States中的S0指非睡眠状态，包含了系统正常运作状态以及待机状态，这意味着只有在S0状态下，C-States才会存在。同样的，C0代表正常工作状态，而P-States正是处理器正常运作时的状态，所以P-States只存在于C0状态下。&lt;/p&gt;

&lt;p&gt;简单来说，P-States是根据系统的负载情况调节处理器核心电压和频率，处理器仍在运作当中；而C-States则是改变处理器各个部分的状态，包括核心、缓存、总线以及各种后来集成进来的模块，此时处理器应该是工作或待机状态。我们日常使用电脑的时候，系统就是频繁地在这些状态下切换，以达到提高续航和降低功耗的目的。&lt;/p&gt;

&lt;h4 id=&#34;c-states各个状态介绍&#34;&gt;C-States各个状态介绍&lt;/h4&gt;

&lt;p&gt;目前C-States有以下这11个状态：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;C0&lt;/strong&gt;：正常运行模式，我们正常操作电脑时均处于C0状态。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;C1/C1E&lt;/strong&gt;：挂起/待机状态，通过软件（一般发送HLT命令）停止处理器内部时钟。增强版的C1E支持降低倍频和电压。使用CPU-Z会观察到频率、电压下降，表示系统进入了这个状态，当外部总线传来请求时就会暂时离开C1/C1E状态（只需10纳秒），处理完后会恢复。这个状态仅对硬件延迟有要求，不过目前的硬件一般都没问题。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;C2/C2E&lt;/strong&gt;：和C1/C1E类似，但C2/C2E状态通过硬件进入，而且唤醒需要100纳秒以上。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;C3&lt;/strong&gt;：深度睡眠，内部时钟同样会被停止，总线频率会被锁定，多核心系统下缓存数据保留，并暂停写入操作，无法响应外部总线的重要请求。进入C3状态的前提是硬件支持并已进入C2模式。唤醒时间在50微秒左右。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;C4&lt;/strong&gt;：更深度睡眠，在C3状态的基础上通过将电压降至1.0V以下与减少L2缓存的数据存储以降低功耗。需要进入C3后才能进入C4，另外唤醒时间不超过1秒。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;C4E&lt;/strong&gt;：同样需要进入C4状态，并且L2缓存数据被减为零。唤醒时间至少需要200微秒。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;C6&lt;/strong&gt;：深度节能，处理器可实时清除L1缓存内所有数据，在保存处理器微架构状态下，关掉内核及L2缓存，芯片组会继续为I/O提供内存交换动作。对各个核心电源进行更智能的管理，电压降至C4的一半。不过唤醒时间要比C4长50%。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;C7&lt;/strong&gt;：更深度节能，在C6的基础上增加了清空部分或者全部L3缓存。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;C8&lt;/strong&gt;：L3缓存、系统助手（也就是以前北桥整合到CPU中的部分）和IO供电都被关闭，外部VR模块电压降至1.2V。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;C9&lt;/strong&gt;：VR模块电压接近0V。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;C10&lt;/strong&gt;：关闭VR模块。（不确定）&lt;/p&gt;

&lt;h3 id=&#34;monitor-mwait指令&#34;&gt;MONITOR/MWAIT指令&lt;/h3&gt;

&lt;h4 id=&#34;会不会有安全问题&#34;&gt;会不会有安全问题&lt;/h4&gt;

&lt;p&gt;&lt;font color=red&gt;&lt;strong&gt;问题：&lt;/strong&gt;&lt;/font&gt;虚拟化下，如果guest kernel中执行了MONITOR gva指令，此时会不会影响到host中正处于mwait状态的cpu？例如：无论是某个vcpu STORE了该gva、或者某个pcpu STORE了某hva（而此hva的数值与该gva相等），都将引起mwait BROKEN?&lt;/p&gt;

&lt;p&gt;&lt;font color=blue&gt;&lt;strong&gt;解决：&lt;/strong&gt;&lt;/font&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;intel SDM vol3 26.3.3 / 27.5.6 说，VMentry/VMexit时会将可能有影响的所有“address-range monitoring”清除。（题外话：什么叫“可能有影响”？&lt;strong&gt;[a]&lt;/strong&gt;我觉得都是“可能有影响的”，因为该address-range是个virtual address，对于64位host+64位guest的线性地址空间大小是一样的，硬件上无法区分，所以应该是都会清除。&lt;strong&gt;[b]&lt;/strong&gt;但是这样的话又不对了，假如pcpu监控了hva1，然后它进入了guest，这时需要将hva1清除，当VMexit后并没有提到恢复对hva1的监控，那么此pcpu上后续STORE hva1不就不能被监控了吗？&lt;strong&gt;[c]&lt;/strong&gt;除非有种可能，address-range由至少二元组确定，即virtual address + cpu mode，但是这样的话SDM何不直接描述为“guest或non-root的address-range清除”即可？&lt;font color=red&gt;哎&amp;hellip;暂时不懂&lt;/font&gt;）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;intel SDM vol3 25.1.3 说，如果VM-execution control的“MONITOR exiting”为1，则MONITOR指令会导致VMexit。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在KVM中，在&lt;code&gt;setup_vmcs_config&lt;/code&gt;中“MONITOR exiting”是会强制为1的，所以vcpu只要执行该指令就会引起VMexit，退出处理&lt;code&gt;handle_monitor&lt;/code&gt;中直接跳过该指令、把它当做NOP来处理。&lt;/p&gt;

&lt;h3 id=&#34;linux-idle进程&#34;&gt;Linux idle进程&lt;/h3&gt;

&lt;h4 id=&#34;执行框架分析&#34;&gt;执行框架分析&lt;/h4&gt;

&lt;h4 id=&#34;intel-idle分析&#34;&gt;intel_idle分析&lt;/h4&gt;
</description>
    </item>
    
  </channel>
</rss>